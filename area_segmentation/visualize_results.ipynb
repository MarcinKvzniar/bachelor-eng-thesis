{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "886991cf",
   "metadata": {},
   "source": [
    "# Teacher vs Ensemble Visualisation\n",
    "Compare predictions from Teacher model (PyTorch) vs Ensemble model (Hard Overlay)\n",
    "Visualize: Original Image, Ground Truth Mask, Teacher Prediction, Ensemble Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eb5e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from pathlib import Path\n",
    "\n",
    "# Suppress TensorFlow logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'\n",
    "\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Configuration\n",
    "IMG_HEIGHT, IMG_WIDTH = 512, 512\n",
    "NUM_CLASSES = 3\n",
    "CLASS_NAMES = ['Background', 'Cancer', 'Other Tissue']\n",
    "\n",
    "PRIMARY_CLASS_COLORS = {\n",
    "    0: (0, 0, 0),           # Black - Background\n",
    "    1: (245, 66, 66),       # Red - Cancer\n",
    "    2: (66, 135, 245),      # Blue - Other tissue\n",
    "}\n",
    "\n",
    "CLASS_MAPPING = {\n",
    "    (0, 0, 0): 0,           # Background - Black\n",
    "    (245, 66, 66): 1,       # Cancer - Red\n",
    "    (255, 0, 0): 1,         # Cancer - Pure red\n",
    "    (66, 135, 245): 2,      # Other Tissue - Blue\n",
    "    (0, 110, 255): 2,       # Other Tissue - Blue variant\n",
    "}\n",
    "\n",
    "INVERSE_CLASS_MAPPING = {v: PRIMARY_CLASS_COLORS[v] for v in range(NUM_CLASSES)}\n",
    "\n",
    "# Model paths\n",
    "GENERALIST_PATH = ''\n",
    "SPECIALIST_PATH = ''\n",
    "TEACHER_PATH = ''\n",
    "\n",
    "print(\"Imports and configuration loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def decode_mask_to_colors(mask):\n",
    "    \"\"\"Convert class mask to RGB color image\"\"\"\n",
    "    color_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "    for class_index, color in INVERSE_CLASS_MAPPING.items():\n",
    "        color_mask[mask == class_index] = color\n",
    "    return color_mask\n",
    "\n",
    "def convert_mask_to_classes(mask_image):\n",
    "    \"\"\"Convert RGB mask image to class indices\"\"\"\n",
    "    mask_classes = np.zeros((mask_image.shape[0], mask_image.shape[1]), dtype=np.uint8)\n",
    "    for color, class_index in CLASS_MAPPING.items():\n",
    "        match = np.all(mask_image == color, axis=-1)\n",
    "        mask_classes[match] = class_index\n",
    "    return mask_classes\n",
    "\n",
    "def load_mask(mask_path):\n",
    "    \"\"\"Load and convert mask to class indices\"\"\"\n",
    "    mask = cv2.imread(mask_path)\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "    mask = convert_mask_to_classes(mask)\n",
    "    return mask\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"Load and normalize image\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    return img / 255.0\n",
    "\n",
    "def build_tf_model():\n",
    "    \"\"\"Build TensorFlow model for generalist/specialist\"\"\"\n",
    "    return sm.Unet('seresnet50', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), \n",
    "                    classes=NUM_CLASSES, activation='softmax', encoder_weights=None)\n",
    "\n",
    "def pad_to_divisible_by_32(array):\n",
    "    \"\"\"Pad array to be divisible by 32\"\"\"\n",
    "    h, w = array.shape[:2]\n",
    "    pad_h = 32 - (h % 32) if h % 32 != 0 else 0\n",
    "    pad_w = 32 - (w % 32) if w % 32 != 0 else 0\n",
    "    if array.ndim == 3:\n",
    "        value = [0, 0, 0]\n",
    "    else:\n",
    "        value = 0\n",
    "    padded = cv2.copyMakeBorder(array, 0, pad_h, 0, pad_w, cv2.BORDER_CONSTANT, value=value)\n",
    "    return padded\n",
    "\n",
    "def get_transforms():\n",
    "    \"\"\"Get albumentations transforms for teacher model\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), \n",
    "                   max_pixel_value=255, p=1.0),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "TEACHER_CLASS_REMAP = {\n",
    "    0: 0, 1: 2, 2: 1, 3: 2, 4: 2, 5: 0\n",
    "}\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625b981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all models\n",
    "print(\"Loading models...\")\n",
    "\n",
    "# TensorFlow models\n",
    "print(\"Loading generalist model...\")\n",
    "model_generalist = build_tf_model()\n",
    "model_generalist.load_weights(GENERALIST_PATH)\n",
    "\n",
    "print(\"Loading specialist model...\")\n",
    "model_specialist = build_tf_model()\n",
    "model_specialist.load_weights(SPECIALIST_PATH)\n",
    "\n",
    "# Teacher model (PyTorch)\n",
    "print(\"Loading teacher model...\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "teacher_model = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b0\",\n",
    "    encoder_weights=None,\n",
    "    classes=6,\n",
    "    activation=None\n",
    ")\n",
    "teacher_model.load_state_dict(torch.load(TEACHER_PATH, map_location=device))\n",
    "teacher_model.eval()\n",
    "teacher_model.to(device)\n",
    "\n",
    "print(\"All models loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c91d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, jaccard_score\n",
    "\n",
    "def find_mask_for_image(image_path):\n",
    "    \"\"\"\n",
    "    Automatically find the corresponding mask for a given image path.\n",
    "    Assumes structure: clean/<case_id>/<image_name> -> mask/<case_id>/<image_name>\n",
    "    \"\"\"\n",
    "    image_path = Path(image_path)\n",
    "    image_name = image_path.name\n",
    "    \n",
    "    case_id = image_path.parent.name\n",
    "    \n",
    "    mask_path = Path(\"\") / case_id / image_name\n",
    "    \n",
    "    if not mask_path.exists():\n",
    "        raise FileNotFoundError(f\"Mask not found for image: {image_path}\\nExpected mask at: {mask_path}\")\n",
    "    \n",
    "    return str(mask_path)\n",
    "\n",
    "def calculate_metrics(gt_mask, pred_mask):\n",
    "    \"\"\"Calculate F1 and IoU metrics between ground truth and prediction\"\"\"\n",
    "    gt_flat = gt_mask.flatten()\n",
    "    pred_flat = pred_mask.flatten()\n",
    "    \n",
    "    f1 = f1_score(gt_flat, pred_flat, average='macro', zero_division=0)\n",
    "    iou = jaccard_score(gt_flat, pred_flat, average='macro', zero_division=0)\n",
    "    \n",
    "    return f1, iou\n",
    "\n",
    "def compare_predictions(image_path):\n",
    "    \"\"\"\n",
    "    Load image, automatically find mask, and evaluate with teacher vs ensemble predictions.\n",
    "    Display 4-panel figure: Original, GT Mask, Teacher Pred, Ensemble Pred\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file. Mask will be automatically located.\n",
    "    \"\"\"\n",
    "    image_path = Path(image_path)\n",
    "    \n",
    "    mask_path = find_mask_for_image(image_path)\n",
    "    \n",
    "    image = load_image(str(image_path))\n",
    "    gt_mask = load_mask(mask_path)\n",
    "    \n",
    "    image_rgb = cv2.imread(str(image_path))\n",
    "    image_rgb = cv2.cvtColor(image_rgb, cv2.COLOR_BGR2RGB)\n",
    "    image_resized = cv2.resize(image_rgb, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    image_padded = pad_to_divisible_by_32(image_resized)\n",
    "    \n",
    "    transforms = get_transforms()\n",
    "    augmented = transforms(image=image_padded)\n",
    "    input_tensor = augmented['image'].unsqueeze(0).to(device, dtype=torch.float32)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_logits = teacher_model(input_tensor)\n",
    "        probs_6class = torch.softmax(output_logits, dim=1)\n",
    "    \n",
    "    probs_3class = torch.zeros((1, 3, probs_6class.shape[2], probs_6class.shape[3]), device=device)\n",
    "    probs_3class[:, 0] = probs_6class[:, 0] + probs_6class[:, 5]  \n",
    "    probs_3class[:, 1] = probs_6class[:, 2]                        \n",
    "    probs_3class[:, 2] = probs_6class[:, 1] + probs_6class[:, 3] + probs_6class[:, 4]  \n",
    "    \n",
    "    teacher_pred = torch.argmax(probs_3class, dim=1).squeeze().cpu().numpy()\n",
    "    teacher_pred = teacher_pred[:IMG_HEIGHT, :IMG_WIDTH]\n",
    "    \n",
    "    image_array = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    probs_gen = model_generalist.predict(image_array, verbose=0)[0]\n",
    "    probs_spec = model_specialist.predict(image_array, verbose=0)[0]\n",
    "    \n",
    "    mask_gen = np.argmax(probs_gen, axis=-1)\n",
    "    mask_spec = np.argmax(probs_spec, axis=-1)\n",
    "    \n",
    "    ensemble_pred = mask_gen.copy()\n",
    "    cancer_indices = (mask_spec == 1)\n",
    "    ensemble_pred[cancer_indices] = 1\n",
    "    \n",
    "    teacher_f1, teacher_iou = calculate_metrics(gt_mask, teacher_pred.astype(np.uint8))\n",
    "    ensemble_f1, ensemble_iou = calculate_metrics(gt_mask, ensemble_pred.astype(np.uint8))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(18, 5))\n",
    "    \n",
    "    # Panel 1: Original Image\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title(\"Original Image\", fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Panel 2: Ground Truth Mask\n",
    "    gt_colored = decode_mask_to_colors(gt_mask)\n",
    "    axes[1].imshow(gt_colored)\n",
    "    axes[1].set_title(\"Ground Truth Mask\", fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Panel 3: Teacher Prediction with metrics\n",
    "    teacher_colored = decode_mask_to_colors(teacher_pred.astype(np.uint8))\n",
    "    axes[2].imshow(teacher_colored)\n",
    "    axes[2].set_title(f\"Teacher \\nF1: {teacher_f1:.3f} | IoU: {teacher_iou:.3f}\", fontsize=12)\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    # Panel 4: Ensemble Prediction with metrics\n",
    "    ensemble_colored = decode_mask_to_colors(ensemble_pred.astype(np.uint8))\n",
    "    axes[3].imshow(ensemble_colored)\n",
    "    axes[3].set_title(f\"Ensemble \\nF1: {ensemble_f1:.3f} | IoU: {ensemble_iou:.3f}\", fontsize=12)\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print file info and metrics\n",
    "    print(f\"\\nImage: {image_path.name}\")\n",
    "    print(f\"   Path: {image_path}\")\n",
    "    print(f\"   Mask: {Path(mask_path).name}\")\n",
    "    print(f\"\\nMetrics:\")\n",
    "    print(f\"   Teacher - F1: {teacher_f1:.4f} | IoU: {teacher_iou:.4f}\")\n",
    "    print(f\"   Ensemble - F1: {ensemble_f1:.4f} | IoU: {ensemble_iou:.4f}\")\n",
    "    \n",
    "    return image, gt_mask, teacher_pred, ensemble_pred, teacher_f1, teacher_iou, ensemble_f1, ensemble_iou\n",
    "\n",
    "print(\"Comparison function refactored with auto mask detection and metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05512792",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_predictions(\n",
    "    \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f262da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_all_images():\n",
    "    \"\"\"\n",
    "    Evaluate all test images and return results sorted by ensemble F1 score (worst first)\n",
    "    \"\"\"\n",
    "    test_image_dir = Path(\"\")\n",
    "    all_images = list(test_image_dir.glob(\"*/*.png\"))\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(f\"Evaluating {len(all_images)} test images...\")\n",
    "    \n",
    "    for i, image_path in enumerate(all_images):\n",
    "        if i % 20 == 0:\n",
    "            print(f\"  Progress: {i}/{len(all_images)} images processed\")\n",
    "        \n",
    "        try:\n",
    "            image_path_str = str(image_path)\n",
    "            \n",
    "            mask_path = find_mask_for_image(image_path_str)\n",
    "            \n",
    "            image = load_image(image_path_str)\n",
    "            gt_mask = load_mask(mask_path)\n",
    "            \n",
    "            image_rgb = cv2.imread(image_path_str)\n",
    "            image_rgb = cv2.cvtColor(image_rgb, cv2.COLOR_BGR2RGB)\n",
    "            image_resized = cv2.resize(image_rgb, (IMG_WIDTH, IMG_HEIGHT))\n",
    "            image_padded = pad_to_divisible_by_32(image_resized)\n",
    "            \n",
    "            transforms = get_transforms()\n",
    "            augmented = transforms(image=image_padded)\n",
    "            input_tensor = augmented['image'].unsqueeze(0).to(device, dtype=torch.float32)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output_logits = teacher_model(input_tensor)\n",
    "                probs_6class = torch.softmax(output_logits, dim=1)\n",
    "            \n",
    "            probs_3class = torch.zeros((1, 3, probs_6class.shape[2], probs_6class.shape[3]), device=device)\n",
    "            probs_3class[:, 0] = probs_6class[:, 0] + probs_6class[:, 5]\n",
    "            probs_3class[:, 1] = probs_6class[:, 2]                        \n",
    "            probs_3class[:, 2] = probs_6class[:, 1] + probs_6class[:, 3] + probs_6class[:, 4]  \n",
    "            \n",
    "            teacher_pred = torch.argmax(probs_3class, dim=1).squeeze().cpu().numpy()\n",
    "            teacher_pred = teacher_pred[:IMG_HEIGHT, :IMG_WIDTH]\n",
    "            \n",
    "            image_array = np.expand_dims(image, axis=0)\n",
    "            \n",
    "            probs_gen = model_generalist.predict(image_array, verbose=0)[0]\n",
    "            probs_spec = model_specialist.predict(image_array, verbose=0)[0]\n",
    "            \n",
    "            mask_gen = np.argmax(probs_gen, axis=-1)\n",
    "            mask_spec = np.argmax(probs_spec, axis=-1)\n",
    "            \n",
    "            ensemble_pred = mask_gen.copy()\n",
    "            cancer_indices = (mask_spec == 1)\n",
    "            ensemble_pred[cancer_indices] = 1\n",
    "            \n",
    "            teacher_f1, teacher_iou = calculate_metrics(gt_mask, teacher_pred.astype(np.uint8))\n",
    "            ensemble_f1, ensemble_iou = calculate_metrics(gt_mask, ensemble_pred.astype(np.uint8))\n",
    "            \n",
    "            results.append({\n",
    "                'image_path': image_path_str,\n",
    "                'mask_path': mask_path,\n",
    "                'case_id': image_path.parent.name,\n",
    "                'image_name': image_path.name,\n",
    "                'teacher_f1': teacher_f1,\n",
    "                'teacher_iou': teacher_iou,\n",
    "                'ensemble_f1': ensemble_f1,\n",
    "                'ensemble_iou': ensemble_iou\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {image_path.name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nEvaluation complete: {len(results)} images successfully processed\")\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df_sorted = df.sort_values('ensemble_f1', ascending=True)\n",
    "    \n",
    "    return df_sorted\n",
    "\n",
    "def showcase_worst_predictions(n=10):\n",
    "    \"\"\"\n",
    "    Find and visualize the N worst predictions based on ensemble F1 score\n",
    "    \n",
    "    Args:\n",
    "        n: Number of worst predictions to show (default 10)\n",
    "    \"\"\"\n",
    "    print(\"Finding worst predictions...\")\n",
    "    \n",
    "    results_df = evaluate_all_images()\n",
    "    \n",
    "    worst_predictions = results_df.head(n)\n",
    "    \n",
    "    print(f\"\\n{n} Worst Ensemble Predictions (by F1 score):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for idx, row in worst_predictions.iterrows():\n",
    "        print(f\"{len(worst_predictions) - list(worst_predictions.index).index(idx)}. {row['image_name']}\")\n",
    "        print(f\"   Case: {row['case_id']}\")\n",
    "        print(f\"   Ensemble F1: {row['ensemble_f1']:.4f} | IoU: {row['ensemble_iou']:.4f}\")\n",
    "        print(f\"   Teacher  F1: {row['teacher_f1']:.4f} | IoU: {row['teacher_iou']:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(f\"   Best Ensemble F1:  {results_df['ensemble_f1'].max():.4f}\")\n",
    "    print(f\"   Worst Ensemble F1: {results_df['ensemble_f1'].min():.4f}\")\n",
    "    print(f\"   Mean Ensemble F1:  {results_df['ensemble_f1'].mean():.4f}\")\n",
    "    print(f\"   Std Ensemble F1:   {results_df['ensemble_f1'].std():.4f}\")\n",
    "    \n",
    "    print(f\"\\nVisualizing {n} worst predictions...\")\n",
    "    \n",
    "    for idx, row in worst_predictions.iterrows():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Rank {len(worst_predictions) - list(worst_predictions.index).index(idx)}: {row['image_name']}\")\n",
    "        print(f\"Ensemble F1: {row['ensemble_f1']:.4f}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        compare_predictions(row['image_path'])\n",
    "    \n",
    "    return results_df, worst_predictions\n",
    "\n",
    "print(\"Worst predictions analysis functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ed8b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df, worst_5 = showcase_worst_predictions(n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".wsl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
