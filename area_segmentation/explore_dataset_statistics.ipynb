{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112bcea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c87e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_paths = [\n",
    "    '',\n",
    "    '',\n",
    "]\n",
    "\n",
    "NUCLEI_COLOR_MAP = {\n",
    "    'Background': (255, 255, 255),    # White\n",
    "    'Negative': (112, 112, 225),      # Blue\n",
    "    'Positive': (250, 62, 62),        # Red\n",
    "    'Boundary': (0, 0, 0),            # Black\n",
    "}\n",
    "\n",
    "AREA_COLOR_MAP = {\n",
    "    'Background': (0, 0, 0),          # Black\n",
    "    'Cancer': (245, 66, 66),          # Red\n",
    "    'Other Tissue': (66, 135, 245),   # Blue\n",
    "}\n",
    "\n",
    "def detect_dataset_type(mask_path):\n",
    "    \"\"\"Detect whether this is nuclei or area segmentation dataset.\"\"\"\n",
    "    path_lower = str(mask_path).lower()\n",
    "    if 'nuclei' in path_lower:\n",
    "        return 'nuclei'\n",
    "    elif 'area' in path_lower:\n",
    "        return 'area'\n",
    "    else:\n",
    "        return 'nuclei'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131b362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mask_statistics(mask_folder_path, dataset_type='area'):\n",
    "    mask_path = Path(mask_folder_path)\n",
    "    \n",
    "    if not mask_path.exists():\n",
    "        print(f\"Error: Path '{mask_path}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    if dataset_type == 'area':\n",
    "        color_map = AREA_COLOR_MAP\n",
    "        class_names = ['Background', 'Cancer', 'Other Tissue']\n",
    "    else: \n",
    "        color_map = NUCLEI_COLOR_MAP\n",
    "        class_names = ['Background', 'Negative', 'Positive', 'Boundary']\n",
    "    \n",
    "    subfolders = [d for d in mask_path.iterdir() if d.is_dir()]\n",
    "    \n",
    "    if not subfolders:\n",
    "        print(\"No subfolders found in mask directory.\")\n",
    "        return\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for subfolder in sorted(subfolders):\n",
    "        mask_files = list(subfolder.glob('*.png'))\n",
    "        \n",
    "        if not mask_files:\n",
    "            continue\n",
    "        \n",
    "        class_pixels = {name: 0 for name in class_names}\n",
    "        \n",
    "        for mask_file in mask_files:\n",
    "            img = Image.open(mask_file).convert('RGB')\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            for class_name, color in color_map.items():\n",
    "                mask = (img_array[:, :, 0] == color[0]) & \\\n",
    "                       (img_array[:, :, 1] == color[1]) & \\\n",
    "                       (img_array[:, :, 2] == color[2])\n",
    "                class_pixels[class_name] += np.sum(mask)\n",
    "        \n",
    "        total_pixels = sum(class_pixels.values())\n",
    "        \n",
    "        if total_pixels > 0:\n",
    "            result = {\n",
    "                'Subfolder': subfolder.name,\n",
    "                'Images': len(mask_files),\n",
    "                'Total Pixels': total_pixels\n",
    "            }\n",
    "            \n",
    "            for class_name in class_names:\n",
    "                result[f'{class_name} (%)'] = (class_pixels[class_name] / total_pixels) * 100\n",
    "                result[f'{class_name}_pixels'] = class_pixels[class_name]\n",
    "            \n",
    "            results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def analyze_multiple_mask_folders(mask_paths_list):\n",
    "    all_results = []\n",
    "    \n",
    "    for mask_path in mask_paths_list:\n",
    "        print(f\"Analyzing: {mask_path}\")\n",
    "        \n",
    "        dataset_type = detect_dataset_type(mask_path)\n",
    "        print(f\"Dataset type: {dataset_type}\")\n",
    "        \n",
    "        df = analyze_mask_statistics(mask_path, dataset_type=dataset_type)\n",
    "        \n",
    "        if df is not None and not df.empty:\n",
    "            df['Source'] = Path(mask_path).name\n",
    "            df['Type'] = dataset_type\n",
    "            all_results.append(df)\n",
    "            print(f\" Found {len(df)} subfolders with {df['Images'].sum()} total images\")\n",
    "        else:\n",
    "            print(f\" No data found in {mask_path}\")\n",
    "    \n",
    "    if not all_results:\n",
    "        print(\"\\n No data found in any of the provided paths\")\n",
    "        return None\n",
    "    \n",
    "    combined_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    print(f\"Combined analysis: {len(all_results)} folders analyzed\\n\")\n",
    "\n",
    "    print(f\"Total subfolders: {len(combined_df)}\")\n",
    "    print(f\"Total images: {combined_df['Images'].sum()}\")\n",
    "    print(f\"Total pixels: {combined_df['Total Pixels'].sum():,}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "df_stats = analyze_multiple_mask_folders(mask_paths)\n",
    "\n",
    "if df_stats is not None and not df_stats.empty:\n",
    "    print(\"Class Distribution Statistics:\\n\")\n",
    "    display_cols = ['Source', 'Type', 'Subfolder', 'Images', 'Total Pixels']\n",
    "    pct_cols = [col for col in df_stats.columns if '(%)' in col]\n",
    "    print(df_stats[display_cols + pct_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd7447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_stats is not None and not df_stats.empty:\n",
    "    print(\"Detailed statistics by source and subfolder:\\n\")\n",
    "    \n",
    "    for source in df_stats['Source'].unique():\n",
    "        source_df = df_stats[df_stats['Source'] == source]\n",
    "        dataset_type = source_df['Type'].iloc[0]\n",
    "        \n",
    "        print(f\"\\n Source: {source} (Type: {dataset_type})\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        pct_cols = [col for col in source_df.columns if '(%)' in col]\n",
    "        pixel_cols = [col for col in source_df.columns if col.endswith('_pixels')]\n",
    "        \n",
    "        for idx, row in source_df.iterrows():\n",
    "            print(f\"   {row['Subfolder']}\")\n",
    "            print(f\"     Images: {row['Images']}\")\n",
    "            \n",
    "            for pct_col in pct_cols:\n",
    "                class_name = pct_col.replace(' (%)', '')\n",
    "                print(f\"     {class_name:20s}: {row[pct_col]:.2f}%\")\n",
    "            \n",
    "            print(f\"     Total Pixels:        {row['Total Pixels']:,}\")\n",
    "            print()\n",
    "    \n",
    "    print(\"Overall statistics by dataset type:\\n\")\n",
    "    \n",
    "    for dataset_type in df_stats['Type'].unique():\n",
    "        type_df = df_stats[df_stats['Type'] == dataset_type]\n",
    "        \n",
    "        total_images = type_df['Images'].sum()\n",
    "        total_pixels = type_df['Total Pixels'].sum()\n",
    "        \n",
    "        print(f\"\\n {dataset_type.upper()} Dataset:\")\n",
    "        print(f\"   Subfolders: {len(type_df)}\")\n",
    "        print(f\"   Total Images: {total_images}\")\n",
    "        print(f\"   Total Pixels: {total_pixels:,}\")\n",
    "        \n",
    "        pixel_cols = [col for col in type_df.columns if col.endswith('_pixels')]\n",
    "        \n",
    "        for pixel_col in pixel_cols:\n",
    "            class_name = pixel_col.replace('_pixels', '')\n",
    "            total_class_pixels = type_df[pixel_col].sum()\n",
    "            pct = (total_class_pixels / total_pixels) * 100 if total_pixels > 0 else 0\n",
    "            print(f\"   {class_name:20s}: {pct:.2f}%\")\n",
    "    \n",
    "    print(\"Overall statistics (all datasets combined):\\n\")\n",
    "\n",
    "    print(f\"Total Sources: {df_stats['Source'].nunique()}\")\n",
    "    print(f\"Total Dataset Types: {df_stats['Type'].nunique()}\")\n",
    "    print(f\"Total Subfolders: {len(df_stats)}\")\n",
    "    print(f\"Total Images: {df_stats['Images'].sum()}\")\n",
    "    print(f\"Total Pixels: {df_stats['Total Pixels'].sum():,}\")\n",
    "    \n",
    "    print(\"Statistics by source:\")\n",
    "    for source in df_stats['Source'].unique():\n",
    "        source_df = df_stats[df_stats['Source'] == source]\n",
    "        source_total_pixels = source_df['Total Pixels'].sum()\n",
    "        dataset_type = source_df['Type'].iloc[0]\n",
    "        \n",
    "        print(f\"\\n {source} ({dataset_type})\")\n",
    "        print(f\"   Subfolders: {len(source_df)}\")\n",
    "        print(f\"   Images: {source_df['Images'].sum()}\")\n",
    "        print(f\"   Pixels: {source_total_pixels:,}\")\n",
    "        \n",
    "        pixel_cols = [col for col in source_df.columns if col.endswith('_pixels')]\n",
    "        \n",
    "        for pixel_col in pixel_cols:\n",
    "            class_name = pixel_col.replace('_pixels', '')\n",
    "            total_class_pixels = source_df[pixel_col].sum()\n",
    "            pct = (total_class_pixels / source_total_pixels) * 100 if source_total_pixels > 0 else 0\n",
    "            print(f\"   {class_name:20s}: {pct:.2f}%\")\n",
    "else:\n",
    "    print(\"No statistics available to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_by_dataset_split(df_stats, train_subfolders=None, val_subfolders=None):\n",
    "    if df_stats is None or df_stats.empty:\n",
    "        raise ValueError(\"df_stats is empty or None\")\n",
    "\n",
    "    if train_subfolders is None and val_subfolders is None:\n",
    "        raise ValueError(\"At least one of train_subfolders or val_subfolders must be provided\")\n",
    "\n",
    "    pixel_cols = [col for col in df_stats.columns if col.endswith('_pixels')]\n",
    "    pct_cols = [col for col in df_stats.columns if '(%)' in col]\n",
    "    \n",
    "    df = df_stats.copy()\n",
    "    \n",
    "    all_subfolders = set(df['Subfolder'].values)\n",
    "    \n",
    "    if train_subfolders is not None:\n",
    "        train_set = set(train_subfolders)\n",
    "        invalid = train_set - all_subfolders\n",
    "        if invalid:\n",
    "            raise ValueError(f\"Train subfolders not found in dataset: {invalid}\")\n",
    "    else:\n",
    "        train_set = set()\n",
    "    \n",
    "    if val_subfolders is not None:\n",
    "        val_set = set(val_subfolders)\n",
    "        invalid = val_set - all_subfolders\n",
    "        if invalid:\n",
    "            raise ValueError(f\"Validation subfolders not found in dataset: {invalid}\")\n",
    "    else:\n",
    "        val_set = set()\n",
    "    \n",
    "    overlap = train_set & val_set\n",
    "    if overlap:\n",
    "        raise ValueError(f\"Subfolders appear in both train and validation: {overlap}\")\n",
    "    \n",
    "    if train_subfolders is not None and val_subfolders is None:\n",
    "        val_set = all_subfolders - train_set\n",
    "    elif val_subfolders is not None and train_subfolders is None:\n",
    "        train_set = all_subfolders - val_set\n",
    "    \n",
    "    assignment = ['Train' if name in train_set else 'Validation' for name in df['Subfolder']]\n",
    "    \n",
    "    base_cols = ['Subfolder', 'Images', 'Total Pixels']\n",
    "    if 'Source' in df.columns:\n",
    "        base_cols.insert(0, 'Source')\n",
    "    if 'Type' in df.columns:\n",
    "        base_cols.insert(1, 'Type')\n",
    "    \n",
    "    df_result = df[base_cols + pct_cols].copy()\n",
    "    df_result['Assigned Set'] = assignment\n",
    "\n",
    "    train_df = df_result[df_result['Assigned Set'] == 'Train']\n",
    "    val_df = df_result[df_result['Assigned Set'] == 'Validation']\n",
    "\n",
    "    def aggregate_stats(group_df, split_name):\n",
    "        if group_df.empty:\n",
    "            return {'Split': split_name, 'Total Images': 0, 'Total Pixels': 0}\n",
    "        \n",
    "        total_pixels = group_df['Total Pixels'].sum()\n",
    "        total_images = group_df['Images'].sum()\n",
    "        \n",
    "        result = {\n",
    "            'Split': split_name,\n",
    "            'Total Images': int(total_images),\n",
    "            'Total Pixels': int(total_pixels)\n",
    "        }\n",
    "        \n",
    "        idxs = group_df.index\n",
    "        original_rows = df.loc[idxs]\n",
    "        \n",
    "        for pixel_col in pixel_cols:\n",
    "            if pixel_col in original_rows.columns:\n",
    "                class_name = pixel_col.replace('_pixels', '')\n",
    "                total_class_pixels = original_rows[pixel_col].sum()\n",
    "                pct = (total_class_pixels / total_pixels) * 100 if total_pixels > 0 else 0.0\n",
    "                result[f'{class_name} (%)'] = pct\n",
    "        \n",
    "        return result\n",
    "\n",
    "    train_stats = aggregate_stats(train_df, 'Train')\n",
    "    val_stats = aggregate_stats(val_df, 'Validation')\n",
    "\n",
    "    print(\"\\nDataset split summary:\")\n",
    "    print(f\"  Train: {train_stats['Total Images']} images, {train_stats['Total Pixels']:,} pixels\")\n",
    "    for key, val in train_stats.items():\n",
    "        if key.endswith('(%)'):\n",
    "            print(f\"    {key}: {val:.2f}%\", end='')\n",
    "    print()\n",
    "    \n",
    "    print(f\"Validation: {val_stats['Total Images']} images, {val_stats['Total Pixels']:,} pixels\")\n",
    "    for key, val in val_stats.items():\n",
    "        if key.endswith('(%)'):\n",
    "            print(f\"    {key}: {val:.2f}%\", end='')\n",
    "    print()\n",
    "\n",
    "    summary_df = pd.DataFrame([train_stats, val_stats])\n",
    "\n",
    "    return df_result.reset_index(drop=True), summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728409b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available subfolders by source:\\n\")\n",
    "for mask_path in mask_paths:\n",
    "    path = Path(mask_path)\n",
    "    if path.exists():\n",
    "        print(f\"{path.name}:\")\n",
    "        for folder in sorted(path.iterdir()):\n",
    "            if folder.is_dir():\n",
    "                print(f\"   - {folder.name}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"Path does not exist: {mask_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e3f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cases = []\n",
    "val_cases = []\n",
    "\n",
    "assigned_df, df_split_stats = analyze_by_dataset_split(df_stats, train_subfolders=train_cases, val_subfolders=val_cases)\n",
    "\n",
    "print(\"\\nDetailed assignment:\")\n",
    "print(assigned_df.to_string(index=False))\n",
    "\n",
    "print(\"Split statistics:\")\n",
    "print(df_split_stats.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".wsl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
